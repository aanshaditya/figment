{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fantasy Football\n",
    "\n",
    "In this notebook, I will make an attempt to predict football stats for the NFL player Tom Brady.\n",
    "These stats could be used in a fantasy football league.\n",
    "\n",
    "This is a continuation of the previous notebook where we defined and created our `sql` database (using the python module `sqlite3`).\n",
    "_Now we do not need to interface with `nflgame` to access the data we want._\n",
    "\n",
    "In this notebook we will load data from the database and make our first predictions.\n",
    "My predictions will be compared with those from Yahoo! and ESPN, and ultimately graded on the actual outcome in each game.\n",
    "\n",
    "_This notebook is aimed for running on Google Colab, so first we need to clone this repository to make the data available -- I don't yet know how to clone a git repository into google colab and then use a notebook from that repository, so this is a bit redundant._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the modules from scikit-learn\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import explained_variance_score  # quantifying accuracy of regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we will now prepare the data for training.  We will use `numpy` to easily calculate averages of the columns for different numbers of rows and feed those into the training.\n",
    "\n",
    "I understand this setup seems a little convoluted:\n",
    "- convert `nflgame` data into `sql` database\n",
    "- load `sql` database and re-calculate data, put into `pandas` dataframe\n",
    "- load into ML tools\n",
    "\n",
    "At the moment I want some practice with `sql`, and I know how to interface `pandas` dataframes with ML tools.   \n",
    "I'm using this ~convoluted workflow as a way to practice with `sql`.  \n",
    "For more developed workflows, I hope to learn more about `sql` and use it directly to interface data with ML tools, or I may just jump straight from `nflgame` into `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vuMrC2xCkO8B"
   },
   "source": [
    "## Learning\n",
    "\n",
    "There are only 16 games per season, so the way I have this structured thus far is likely not the most ideal for predicting outcomes.  \n",
    "Instead, I can imagine a better way would involve using individual plays categorized by many features, e.g., {field position, score, quarter+time remaining, down+distance, OFF/DEF formation, home/away, current stats, and metrics for the game's progression} for both the player of interest and the defense of interest.  \n",
    "If I have the time, I will investigate such an approach.  For now, I will keep it simple and just use aggregated game information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g-rkdrslBAB2"
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(sqlite_file)\n",
    "dfs  = {} # contain `sql` database tables as individual dataframes (in a dictionary)\n",
    "for key in unique_opps+[\"tb12\"]:\n",
    "    dfs[key] = pd.read_sql(\"SELECT * FROM {0}\".format(key), conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xj7mKue0Eai-"
   },
   "source": [
    "Now let's update the dataframe so that rows 2-15 represent the averages of all the previous data (week 1 will just be as it is, we won't make predictions for that week)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1541781364154,
     "user": {
      "displayName": "Daniel Marley",
      "photoUrl": "https://lh5.googleusercontent.com/-x0vVAUeK8iE/AAAAAAAAAAI/AAAAAAAAABo/BoFiYjkoupU/s64/photo.jpg",
      "userId": "07016772076441564573"
     },
     "user_tz": 360
    },
    "id": "8TgkcILVHgck",
    "outputId": "0a8892f0-c80d-42e3-da05-e978281be32a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    passing_tds  fumbles_lost  passer_rating  passing_att  passing_cmp  \\\n",
      "0             3             0          120.9           35           25   \n",
      "1             2             1           72.5           36           20   \n",
      "2             3             0          142.6           27           21   \n",
      "3             1             0          107.1           24           19   \n",
      "4             1             0           69.5           44           27   \n",
      "5             1             0           82.7           32           19   \n",
      "6             1             0          100.8           27           16   \n",
      "7             2             0           90.5           36           19   \n",
      "8             3             0          125.1           43           30   \n",
      "9             2             0          123.1           25           19   \n",
      "10            4             0          158.3           27           21   \n",
      "11            4             0          148.9           29           21   \n",
      "12            2             0          113.4           40           27   \n",
      "13            2             0          110.2           24           15   \n",
      "14            3             0          107.0           27           15   \n",
      "15            2             0          145.6           16           10   \n",
      "\n",
      "    passing_ints  passing_yds  rushing_att  rushing_tds  rushing_yds  \n",
      "0              0          258            0            0            0  \n",
      "1              2          248            0            0            0  \n",
      "2              0          252            4            0            6  \n",
      "3              0          153            5            0            6  \n",
      "4              2          292            2            0            1  \n",
      "5              0          159            2            0            1  \n",
      "6              0          240            4            0           -3  \n",
      "7              0          224            1            0            1  \n",
      "8              0          350            1            1            3  \n",
      "9              0          186            4            0           -2  \n",
      "10             0          341            4            0            1  \n",
      "11             0          326            1            0            3  \n",
      "12             0          369            0            0            0  \n",
      "13             0          163            0            0            0  \n",
      "14             0          140            3            0           13  \n",
      "15             0          199            0            0            0  \n"
     ]
    }
   ],
   "source": [
    "df_tb12 = dfs['tb12']\n",
    "print df_tb12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1541781419994,
     "user": {
      "displayName": "Daniel Marley",
      "photoUrl": "https://lh5.googleusercontent.com/-x0vVAUeK8iE/AAAAAAAAAAI/AAAAAAAAABo/BoFiYjkoupU/s64/photo.jpg",
      "userId": "07016772076441564573"
     },
     "user_tz": 360
    },
    "id": "51OkmgoYHlQu",
    "outputId": "b3fdc897-f744-4290-936c-e2df822fef2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [] nan\n",
      "2 [0] 0.0\n",
      "0 [0 2] 1.0\n",
      "0 [0 2 0] 0.6666666666666666\n",
      "2 [0 2 0 0] 0.5\n",
      "0 [0 2 0 0 2] 0.8\n",
      "0 [0 2 0 0 2 0] 0.6666666666666666\n",
      "0 [0 2 0 0 2 0 0] 0.5714285714285714\n",
      "0 [0 2 0 0 2 0 0 0] 0.5\n",
      "0 [0 2 0 0 2 0 0 0 0] 0.4444444444444444\n",
      "0 [0 2 0 0 2 0 0 0 0 0] 0.4\n",
      "0 [0 2 0 0 2 0 0 0 0 0 0] 0.36363636363636365\n",
      "0 [0 2 0 0 2 0 0 0 0 0 0 0] 0.3333333333333333\n",
      "0 [0 2 0 0 2 0 0 0 0 0 0 0 0] 0.3076923076923077\n",
      "0 [0 2 0 0 2 0 0 0 0 0 0 0 0 0] 0.2857142857142857\n",
      "0 [0 2 0 0 2 0 0 0 0 0 0 0 0 0 0] 0.26666666666666666\n",
      "\n",
      "16 [0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.8, 0.6666666666666666, 0.5714285714285714, 0.5, 0.4444444444444444, 0.4, 0.36363636363636365, 0.3333333333333333, 0.3076923076923077, 0.2857142857142857, 0.26666666666666666]\n"
     ]
    }
   ],
   "source": [
    "# testing code for calculating averages:\n",
    "updated_values = []\n",
    "values = df_tb12['passing_ints'].values\n",
    "for v,value in enumerate(values):\n",
    "    print value,values[:v],np.mean(values[:v])\n",
    "    if v>0:\n",
    "        updated_values.append(np.mean(values[:v]))\n",
    "    else:\n",
    "        updated_values.append(value)\n",
    "print\n",
    "print len(updated_values),updated_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_kFTITgZ5gm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-7KIFHxkZYG"
   },
   "source": [
    "#### Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwW0aAts4pS5"
   },
   "source": [
    "With all of the data nicely organized into a SQLite database, let's use pandas to easily read that and prepare for our learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-CnHJD-rj3a1"
   },
   "outputs": [],
   "source": [
    "df  = df.fillna(-1)\n",
    "tmp = df.sample(frac=1) # shuffle the dataframe rows\n",
    "tts = train_test_split(df[features].values,\\\n",
    "                       df['SalePrice'].values, \\\n",
    "                       test_size=0.25)\n",
    "X_train,X_test,Y_train,Y_test = tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hx-T91dqkbMD"
   },
   "source": [
    "#### Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZrdyxWNHkFCR"
   },
   "outputs": [],
   "source": [
    "# Develop the scaling on the training dataset, and then apply the same shift to the test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scale features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# scale target values\n",
    "scaler_target = StandardScaler()\n",
    "scaler_target.fit(Y_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emGCAY_nkHXc"
   },
   "outputs": [],
   "source": [
    "# Scale values\n",
    "X_test_scale  = scaler.transform(X_test)\n",
    "Y_test_scale  = scaler_target.transform([Y_test])\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "Y_train_scale = scaler_target.transform([Y_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6a6SkvtgkRDF"
   },
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mBebUNCbj6Ym"
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "n_neighbors = 5\n",
    "weights = 'uniform'\n",
    "\n",
    "knn  = neighbors.KNeighborsRegressor(n_neighbors, weights=weights)\n",
    "fknn = knn.fit(X_train, Y_train)\n",
    "predictions = fknn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVg98QiKkS5U"
   },
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_UlP0ipjlGp"
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "# with scikit-learn it is incredibly easy to get started\n",
    "clf = svm.SVR()  # support vector regression\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXy09lEwjqQT"
   },
   "outputs": [],
   "source": [
    "# Performance\n",
    "predictions = clf.predict(X_test)\n",
    "values = np.divide((np.asarray(predictions) - Y_test),Y_test)\n",
    "\n",
    "fig,ax = plt.subplots(2,1,figsize=(8,8))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.hist(values,bins=20,normed=True)\n",
    "plt.xlabel(\"(Pred-Real)/Real\",position=(1,0),ha='right')\n",
    "plt.ylabel(\"AU\",position=(0,1),ha='right')\n",
    "plt.text(0.97,0.90,\"SVM Non-scaled Values\",ha='right',transform=ax[0].transAxes)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.scatter(predictions,Y_test,color='b',edgecolor='k',alpha=0.5,label=\"Test Dataset\");\n",
    "plt.plot(Y_test,Y_test,color='r',label=\"Perfect\")\n",
    "plt.xlim(min(predictions)-10000,max(predictions)+10000)\n",
    "plt.ylim(0,max(Y_test)+20000)\n",
    "plt.xlabel(\"Predicted Sale Price\",position=(1,0),ha='right')\n",
    "plt.ylabel(\"Real Sale Price\",position=(0,1),ha='right')\n",
    "plt.legend()\n",
    "\n",
    "evs = explained_variance_score(Y_test,predictions)\n",
    "\n",
    "print(r\"Distribution = {0:.3f} $\\pm$ {1:.4f}\".format(np.mean(values),np.std(values)))\n",
    "print(r\"EV Score     = {0:.3f}\".format(evs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
